{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1 (3 scores):\n",
    "\n",
    "- Use the Numpy library only to construct the Linear Regression model.\n",
    "- Train and Evaluate that Linear Regression model on the [Forest Fires](https://archive.ics.uci.edu/static/public/162/forest+fires.zip) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2 (3 scores):\n",
    "\n",
    "- Standardize the data so that their mean is $0$ and their variance is $1$.\n",
    "- Compare the results of Linear Regression model when being trained on the original and standardized data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OLS estimator of a linear regression model has the form\n",
    "\n",
    "$$\n",
    "    \\hat{\\beta} = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "where $X^T X \\in \\mathbb{R}^{K \\times K}$ is called the normal matrix of the **Gram Matrix**.\n",
    "\n",
    "Considering the convariance of $X$, we have\n",
    "\n",
    "\\begin{align}\n",
    "    Cov(X)  & = \\mathbb{E}[(X - \\mathbb{E}[X])^2] \\\\\n",
    "            & = \\mathbb{E}[X^T X - 2 X^T\\mathbb{E}[X] + \\mathbb{E}[X]^T \\mathbb{E}[X]] \\\\\n",
    "            & = \\mathbb{E}[X^T X] - 2 \\mathbb{E}[X^T\\mathbb{E}[X]] + \\mathbb{E}[X]^T \\mathbb{E}[X] \\\\\n",
    "            & = \\mathbb{E}[X^T X] - 2 \\mathbb{E}[X]^T\\mathbb{E}[X] + \\mathbb{E}[X]^T \\mathbb{E}[X] \\\\\n",
    "            & = \\mathbb{E}[X^T X] - \\mathbb{E}[X]^T \\mathbb{E}[X] \\\\\n",
    "\\end{align}\n",
    "\n",
    "In case we have $\\mathbb{E}[X] = 0$, then $X^T X = Cov(X)$. The normalization helps we to have the numerical stability of the input, theoretically leads to stable calculation when being applied to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3 (2 scores):\n",
    "\n",
    "- Perform feature engineering to remove columns that are linearly dependent (colinear) with other columns in the dataset.\n",
    "- Evaluate the Linear Regression model when beeing trained on the original data and preprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the Problem of Colinearity\n",
    "\n",
    "As stated previously, the OLS of the linear regression model is achieved by assuming that $rank(X) = K$ or $det(X) \\ne 0$. So that removing columns in $X$ having colinearity with other columns is to ensure that assumption of the full rank condition of $X$. In the case $det(X) = 0$, then the **Moore-Penrose inverse** will be applied to determine the pseudo-inverse matrix of $X^T X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4 (2 scores):\n",
    "\n",
    "- Implement the Linear Regression model using Machine Learning libraries (Scikit Learn or SKorch).\n",
    "- Compare the results of Linear Regression model constructed manually and from Machine Learning libraries."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
